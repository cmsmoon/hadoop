#
# Autogenerated by Thrift
#
# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
#
require 5.6.0;
use strict;
use warnings;
use Thrift;

use Hadoop::API::Types;
use Hadoop::API::HadoopServiceBase;

# HELPER FUNCTIONS AND STRUCTURES

package Hadoop::API::Namenode_chmod_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_chmod_args->mk_accessors( qw( ctx path perms ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{perms} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{perms}) {
    $self->{perms} = $vals->{perms};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_chmod_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::I16) {
      $xfer += $input->readI16(\$self->{perms});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_chmod_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{perms}) {
  $xfer += $output->writeFieldBegin('perms', TType::I16, 2);
  $xfer += $output->writeI16($self->{perms});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_chmod_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_chmod_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_chmod_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_chmod_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_chown_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_chown_args->mk_accessors( qw( ctx path owner group ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{owner} = undef;
$self->{group} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{owner}) {
    $self->{owner} = $vals->{owner};
  }
  if (defined $vals->{group}) {
    $self->{group} = $vals->{group};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_chown_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{owner});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^3$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{group});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_chown_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{owner}) {
  $xfer += $output->writeFieldBegin('owner', TType::STRING, 2);
  $xfer += $output->writeString($self->{owner});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{group}) {
  $xfer += $output->writeFieldBegin('group', TType::STRING, 3);
  $xfer += $output->writeString($self->{group});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_chown_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_chown_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_chown_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_chown_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_df_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_df_args->mk_accessors( qw( ctx ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_df_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_df_args');
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_df_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_df_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_df_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::LIST) {
      {
        my $_size71 = 0;
        $self->{success} = [];
        my $_etype74 = 0;
        $xfer += $input->readListBegin(\$_etype74, \$_size71);
        for (my $_i75 = 0; $_i75 < $_size71; ++$_i75)
        {
          my $elem76 = undef;
          $xfer += $input->readI64(\$elem76);
          push(@{$self->{success}},$elem76);
        }
        $xfer += $input->readListEnd();
      }
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_df_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::LIST, 0);
  {
    $output->writeListBegin(TType::I64, scalar(@{$self->{success}}));
    {
      foreach my $iter77 (@{$self->{success}}) 
      {
        $xfer += $output->writeI64($iter77);
      }
    }
    $output->writeListEnd();
  }
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_enterSafeMode_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_enterSafeMode_args->mk_accessors( qw( ctx ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_enterSafeMode_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_enterSafeMode_args');
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_enterSafeMode_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_enterSafeMode_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_enterSafeMode_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_enterSafeMode_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getBlocks_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getBlocks_args->mk_accessors( qw( ctx path offset length ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{offset} = undef;
$self->{length} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{offset}) {
    $self->{offset} = $vals->{offset};
  }
  if (defined $vals->{length}) {
    $self->{length} = $vals->{length};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getBlocks_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::I64) {
      $xfer += $input->readI64(\$self->{offset});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^3$/ && do{    if ($ftype == TType::I64) {
      $xfer += $input->readI64(\$self->{length});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getBlocks_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{offset}) {
  $xfer += $output->writeFieldBegin('offset', TType::I64, 2);
  $xfer += $output->writeI64($self->{offset});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{length}) {
  $xfer += $output->writeFieldBegin('length', TType::I64, 3);
  $xfer += $output->writeI64($self->{length});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getBlocks_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getBlocks_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getBlocks_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::LIST) {
      {
        my $_size78 = 0;
        $self->{success} = [];
        my $_etype81 = 0;
        $xfer += $input->readListBegin(\$_etype81, \$_size78);
        for (my $_i82 = 0; $_i82 < $_size78; ++$_i82)
        {
          my $elem83 = undef;
          $elem83 = new Hadoop::API::Block();
          $xfer += $elem83->read($input);
          push(@{$self->{success}},$elem83);
        }
        $xfer += $input->readListEnd();
      }
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getBlocks_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::LIST, 0);
  {
    $output->writeListBegin(TType::STRUCT, scalar(@{$self->{success}}));
    {
      foreach my $iter84 (@{$self->{success}}) 
      {
        $xfer += ${iter84}->write($output);
      }
    }
    $output->writeListEnd();
  }
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getDatanodeReport_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getDatanodeReport_args->mk_accessors( qw( ctx type ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{type} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{type}) {
    $self->{type} = $vals->{type};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getDatanodeReport_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::I32) {
      $xfer += $input->readI32(\$self->{type});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getDatanodeReport_args');
if (defined $self->{type}) {
  $xfer += $output->writeFieldBegin('type', TType::I32, 1);
  $xfer += $output->writeI32($self->{type});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getDatanodeReport_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getDatanodeReport_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getDatanodeReport_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::LIST) {
      {
        my $_size85 = 0;
        $self->{success} = [];
        my $_etype88 = 0;
        $xfer += $input->readListBegin(\$_etype88, \$_size85);
        for (my $_i89 = 0; $_i89 < $_size85; ++$_i89)
        {
          my $elem90 = undef;
          $elem90 = new Hadoop::API::DatanodeInfo();
          $xfer += $elem90->read($input);
          push(@{$self->{success}},$elem90);
        }
        $xfer += $input->readListEnd();
      }
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getDatanodeReport_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::LIST, 0);
  {
    $output->writeListBegin(TType::STRUCT, scalar(@{$self->{success}}));
    {
      foreach my $iter91 (@{$self->{success}}) 
      {
        $xfer += ${iter91}->write($output);
      }
    }
    $output->writeListEnd();
  }
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getHealthReport_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getHealthReport_args->mk_accessors( qw( ctx ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getHealthReport_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getHealthReport_args');
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getHealthReport_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getHealthReport_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getHealthReport_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{success} = new Hadoop::API::DFSHealthReport();
      $xfer += $self->{success}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getHealthReport_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::STRUCT, 0);
  $xfer += $self->{success}->write($output);
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getPreferredBlockSize_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getPreferredBlockSize_args->mk_accessors( qw( ctx path ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getPreferredBlockSize_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getPreferredBlockSize_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_getPreferredBlockSize_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_getPreferredBlockSize_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_getPreferredBlockSize_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::I64) {
      $xfer += $input->readI64(\$self->{success});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_getPreferredBlockSize_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::I64, 0);
  $xfer += $output->writeI64($self->{success});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_isInSafeMode_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_isInSafeMode_args->mk_accessors( qw( ctx ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_isInSafeMode_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_isInSafeMode_args');
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_isInSafeMode_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_isInSafeMode_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_isInSafeMode_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::BOOL) {
      $xfer += $input->readBool(\$self->{success});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_isInSafeMode_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::BOOL, 0);
  $xfer += $output->writeBool($self->{success});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_leaveSafeMode_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_leaveSafeMode_args->mk_accessors( qw( ctx ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_leaveSafeMode_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_leaveSafeMode_args');
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_leaveSafeMode_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_leaveSafeMode_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_leaveSafeMode_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_leaveSafeMode_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_ls_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_ls_args->mk_accessors( qw( ctx path ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_ls_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_ls_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_ls_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_ls_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_ls_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::LIST) {
      {
        my $_size92 = 0;
        $self->{success} = [];
        my $_etype95 = 0;
        $xfer += $input->readListBegin(\$_etype95, \$_size92);
        for (my $_i96 = 0; $_i96 < $_size92; ++$_i96)
        {
          my $elem97 = undef;
          $elem97 = new Hadoop::API::Stat();
          $xfer += $elem97->read($input);
          push(@{$self->{success}},$elem97);
        }
        $xfer += $input->readListEnd();
      }
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_ls_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::LIST, 0);
  {
    $output->writeListBegin(TType::STRUCT, scalar(@{$self->{success}}));
    {
      foreach my $iter98 (@{$self->{success}}) 
      {
        $xfer += ${iter98}->write($output);
      }
    }
    $output->writeListEnd();
  }
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_mkdirhier_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_mkdirhier_args->mk_accessors( qw( ctx path perms ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{perms} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{perms}) {
    $self->{perms} = $vals->{perms};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_mkdirhier_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::I16) {
      $xfer += $input->readI16(\$self->{perms});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_mkdirhier_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{perms}) {
  $xfer += $output->writeFieldBegin('perms', TType::I16, 2);
  $xfer += $output->writeI16($self->{perms});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_mkdirhier_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_mkdirhier_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_mkdirhier_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::BOOL) {
      $xfer += $input->readBool(\$self->{success});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_mkdirhier_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::BOOL, 0);
  $xfer += $output->writeBool($self->{success});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_refreshNodes_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_refreshNodes_args->mk_accessors( qw( ctx ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_refreshNodes_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_refreshNodes_args');
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_refreshNodes_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_refreshNodes_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_refreshNodes_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_refreshNodes_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_rename_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_rename_args->mk_accessors( qw( ctx path newPath ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{newPath} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{newPath}) {
    $self->{newPath} = $vals->{newPath};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_rename_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{newPath});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_rename_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{newPath}) {
  $xfer += $output->writeFieldBegin('newPath', TType::STRING, 2);
  $xfer += $output->writeString($self->{newPath});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_rename_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_rename_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_rename_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::BOOL) {
      $xfer += $input->readBool(\$self->{success});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_rename_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::BOOL, 0);
  $xfer += $output->writeBool($self->{success});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_reportBadBlocks_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_reportBadBlocks_args->mk_accessors( qw( ctx blocks ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{blocks} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{blocks}) {
    $self->{blocks} = $vals->{blocks};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_reportBadBlocks_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::LIST) {
      {
        my $_size99 = 0;
        $self->{blocks} = [];
        my $_etype102 = 0;
        $xfer += $input->readListBegin(\$_etype102, \$_size99);
        for (my $_i103 = 0; $_i103 < $_size99; ++$_i103)
        {
          my $elem104 = undef;
          $elem104 = new Hadoop::API::Block();
          $xfer += $elem104->read($input);
          push(@{$self->{blocks}},$elem104);
        }
        $xfer += $input->readListEnd();
      }
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_reportBadBlocks_args');
if (defined $self->{blocks}) {
  $xfer += $output->writeFieldBegin('blocks', TType::LIST, 1);
  {
    $output->writeListBegin(TType::STRUCT, scalar(@{$self->{blocks}}));
    {
      foreach my $iter105 (@{$self->{blocks}}) 
      {
        $xfer += ${iter105}->write($output);
      }
    }
    $output->writeListEnd();
  }
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_reportBadBlocks_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_reportBadBlocks_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_reportBadBlocks_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_reportBadBlocks_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_stat_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_stat_args->mk_accessors( qw( ctx path ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_stat_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_stat_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_stat_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_stat_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_stat_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{success} = new Hadoop::API::Stat();
      $xfer += $self->{success}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_stat_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::STRUCT, 0);
  $xfer += $self->{success}->write($output);
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_setQuota_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_setQuota_args->mk_accessors( qw( ctx path namespaceQuota diskspaceQuota ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{namespaceQuota} = undef;
$self->{diskspaceQuota} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{namespaceQuota}) {
    $self->{namespaceQuota} = $vals->{namespaceQuota};
  }
  if (defined $vals->{diskspaceQuota}) {
    $self->{diskspaceQuota} = $vals->{diskspaceQuota};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_setQuota_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::I64) {
      $xfer += $input->readI64(\$self->{namespaceQuota});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^3$/ && do{    if ($ftype == TType::I64) {
      $xfer += $input->readI64(\$self->{diskspaceQuota});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_setQuota_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{namespaceQuota}) {
  $xfer += $output->writeFieldBegin('namespaceQuota', TType::I64, 2);
  $xfer += $output->writeI64($self->{namespaceQuota});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{diskspaceQuota}) {
  $xfer += $output->writeFieldBegin('diskspaceQuota', TType::I64, 3);
  $xfer += $output->writeI64($self->{diskspaceQuota});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_setQuota_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_setQuota_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_setQuota_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_setQuota_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_setReplication_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_setReplication_args->mk_accessors( qw( ctx path replication ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{replication} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{replication}) {
    $self->{replication} = $vals->{replication};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_setReplication_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::I16) {
      $xfer += $input->readI16(\$self->{replication});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_setReplication_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{replication}) {
  $xfer += $output->writeFieldBegin('replication', TType::I16, 2);
  $xfer += $output->writeI16($self->{replication});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_setReplication_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_setReplication_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_setReplication_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::BOOL) {
      $xfer += $input->readBool(\$self->{success});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_setReplication_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::BOOL, 0);
  $xfer += $output->writeBool($self->{success});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_unlink_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_unlink_args->mk_accessors( qw( ctx path recursive ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{recursive} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{recursive}) {
    $self->{recursive} = $vals->{recursive};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_unlink_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::BOOL) {
      $xfer += $input->readBool(\$self->{recursive});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_unlink_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{recursive}) {
  $xfer += $output->writeFieldBegin('recursive', TType::BOOL, 2);
  $xfer += $output->writeBool($self->{recursive});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_unlink_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_unlink_result->mk_accessors( qw( success ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{success} = undef;
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{success}) {
    $self->{success} = $vals->{success};
  }
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_unlink_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^0$/ && do{    if ($ftype == TType::BOOL) {
      $xfer += $input->readBool(\$self->{success});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_unlink_result');
if (defined $self->{success}) {
  $xfer += $output->writeFieldBegin('success', TType::BOOL, 0);
  $xfer += $output->writeBool($self->{success});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_utime_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_utime_args->mk_accessors( qw( ctx path atime mtime ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{ctx} = undef;
$self->{path} = undef;
$self->{atime} = undef;
$self->{mtime} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{ctx}) {
    $self->{ctx} = $vals->{ctx};
  }
  if (defined $vals->{path}) {
    $self->{path} = $vals->{path};
  }
  if (defined $vals->{atime}) {
    $self->{atime} = $vals->{atime};
  }
  if (defined $vals->{mtime}) {
    $self->{mtime} = $vals->{mtime};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_utime_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^10$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{ctx} = new Hadoop::API::RequestContext();
      $xfer += $self->{ctx}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{path});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::I64) {
      $xfer += $input->readI64(\$self->{atime});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^3$/ && do{    if ($ftype == TType::I64) {
      $xfer += $input->readI64(\$self->{mtime});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_utime_args');
if (defined $self->{path}) {
  $xfer += $output->writeFieldBegin('path', TType::STRING, 1);
  $xfer += $output->writeString($self->{path});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{atime}) {
  $xfer += $output->writeFieldBegin('atime', TType::I64, 2);
  $xfer += $output->writeI64($self->{atime});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{mtime}) {
  $xfer += $output->writeFieldBegin('mtime', TType::I64, 3);
  $xfer += $output->writeI64($self->{mtime});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{ctx}) {
  $xfer += $output->writeFieldBegin('ctx', TType::STRUCT, 10);
  $xfer += $self->{ctx}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_utime_result;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_utime_result->mk_accessors( qw( ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{err} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{err}) {
    $self->{err} = $vals->{err};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_utime_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRUCT) {
      $self->{err} = new Hadoop::API::IOException();
      $xfer += $self->{err}->read($input);
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_utime_result');
if (defined $self->{err}) {
  $xfer += $output->writeFieldBegin('err', TType::STRUCT, 1);
  $xfer += $self->{err}->write($output);
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_datanodeUp_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_datanodeUp_args->mk_accessors( qw( name storage thriftPort ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{name} = undef;
$self->{storage} = undef;
$self->{thriftPort} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{name}) {
    $self->{name} = $vals->{name};
  }
  if (defined $vals->{storage}) {
    $self->{storage} = $vals->{storage};
  }
  if (defined $vals->{thriftPort}) {
    $self->{thriftPort} = $vals->{thriftPort};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_datanodeUp_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{name});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{storage});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^3$/ && do{    if ($ftype == TType::I32) {
      $xfer += $input->readI32(\$self->{thriftPort});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_datanodeUp_args');
if (defined $self->{name}) {
  $xfer += $output->writeFieldBegin('name', TType::STRING, 1);
  $xfer += $output->writeString($self->{name});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{storage}) {
  $xfer += $output->writeFieldBegin('storage', TType::STRING, 2);
  $xfer += $output->writeString($self->{storage});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{thriftPort}) {
  $xfer += $output->writeFieldBegin('thriftPort', TType::I32, 3);
  $xfer += $output->writeI32($self->{thriftPort});
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_datanodeUp_result;
use Class::Accessor;
use base('Class::Accessor');
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
return bless($self,$classname);
}

sub getName {
  return 'Namenode_datanodeUp_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_datanodeUp_result');
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_datanodeDown_args;
use Class::Accessor;
use base('Class::Accessor');
Hadoop::API::Namenode_datanodeDown_args->mk_accessors( qw( name storage thriftPort ) );
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
$self->{name} = undef;
$self->{storage} = undef;
$self->{thriftPort} = undef;
if (UNIVERSAL::isa($vals,'HASH')) {
  if (defined $vals->{name}) {
    $self->{name} = $vals->{name};
  }
  if (defined $vals->{storage}) {
    $self->{storage} = $vals->{storage};
  }
  if (defined $vals->{thriftPort}) {
    $self->{thriftPort} = $vals->{thriftPort};
  }
}
return bless($self,$classname);
}

sub getName {
  return 'Namenode_datanodeDown_args';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
    /^1$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{name});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^2$/ && do{    if ($ftype == TType::STRING) {
      $xfer += $input->readString(\$self->{storage});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
    /^3$/ && do{    if ($ftype == TType::I32) {
      $xfer += $input->readI32(\$self->{thriftPort});
    } else {
      $xfer += $input->skip($ftype);
    }
    last; };
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_datanodeDown_args');
if (defined $self->{name}) {
  $xfer += $output->writeFieldBegin('name', TType::STRING, 1);
  $xfer += $output->writeString($self->{name});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{storage}) {
  $xfer += $output->writeFieldBegin('storage', TType::STRING, 2);
  $xfer += $output->writeString($self->{storage});
  $xfer += $output->writeFieldEnd();
}
if (defined $self->{thriftPort}) {
  $xfer += $output->writeFieldBegin('thriftPort', TType::I32, 3);
  $xfer += $output->writeI32($self->{thriftPort});
  $xfer += $output->writeFieldEnd();
}
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::Namenode_datanodeDown_result;
use Class::Accessor;
use base('Class::Accessor');
sub new {
my $classname = shift;
my $self      = {};
my $vals      = shift || {};
return bless($self,$classname);
}

sub getName {
  return 'Namenode_datanodeDown_result';
}

sub read {
my $self  = shift;
my $input = shift;
my $xfer  = 0;
my $fname;
my $ftype = 0;
my $fid   = 0;
$xfer += $input->readStructBegin(\$fname);
while (1) 
{
  $xfer += $input->readFieldBegin(\$fname, \$ftype, \$fid);
  if ($ftype == TType::STOP) {
    last;
  }
  SWITCH: for($fid)
  {
      $xfer += $input->skip($ftype);
  }
  $xfer += $input->readFieldEnd();
}
$xfer += $input->readStructEnd();
return $xfer;
}

sub write {
my $self   = shift;
my $output = shift;
my $xfer   = 0;
$xfer += $output->writeStructBegin('Namenode_datanodeDown_result');
$xfer += $output->writeFieldStop();
$xfer += $output->writeStructEnd();
return $xfer;
}

package Hadoop::API::NamenodeIf;
use base('Hadoop::API::HadoopServiceBaseIf');
sub chmod{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $perms = shift;

  die 'implement interface';
}
sub chown{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $owner = shift;
  my $group = shift;

  die 'implement interface';
}
sub df{
  my $self = shift;
  my $ctx = shift;

  die 'implement interface';
}
sub enterSafeMode{
  my $self = shift;
  my $ctx = shift;

  die 'implement interface';
}
sub getBlocks{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $offset = shift;
  my $length = shift;

  die 'implement interface';
}
sub getDatanodeReport{
  my $self = shift;
  my $ctx = shift;
  my $type = shift;

  die 'implement interface';
}
sub getHealthReport{
  my $self = shift;
  my $ctx = shift;

  die 'implement interface';
}
sub getPreferredBlockSize{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

  die 'implement interface';
}
sub isInSafeMode{
  my $self = shift;
  my $ctx = shift;

  die 'implement interface';
}
sub leaveSafeMode{
  my $self = shift;
  my $ctx = shift;

  die 'implement interface';
}
sub ls{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

  die 'implement interface';
}
sub mkdirhier{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $perms = shift;

  die 'implement interface';
}
sub refreshNodes{
  my $self = shift;
  my $ctx = shift;

  die 'implement interface';
}
sub rename{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $newPath = shift;

  die 'implement interface';
}
sub reportBadBlocks{
  my $self = shift;
  my $ctx = shift;
  my $blocks = shift;

  die 'implement interface';
}
sub stat{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

  die 'implement interface';
}
sub setQuota{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $namespaceQuota = shift;
  my $diskspaceQuota = shift;

  die 'implement interface';
}
sub setReplication{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $replication = shift;

  die 'implement interface';
}
sub unlink{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $recursive = shift;

  die 'implement interface';
}
sub utime{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $atime = shift;
  my $mtime = shift;

  die 'implement interface';
}
sub datanodeUp{
  my $self = shift;
  my $name = shift;
  my $storage = shift;
  my $thriftPort = shift;

  die 'implement interface';
}
sub datanodeDown{
  my $self = shift;
  my $name = shift;
  my $storage = shift;
  my $thriftPort = shift;

  die 'implement interface';
}
package Hadoop::API::NamenodeRest;
use base('Hadoop::API::HadoopServiceBaseRest');
sub chmod{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $perms = ($request->{'perms'}) ? $request->{'perms'} : undef;
return $self->{impl}->chmod($ctx, $path, $perms);
}

sub chown{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $owner = ($request->{'owner'}) ? $request->{'owner'} : undef;
my $group = ($request->{'group'}) ? $request->{'group'} : undef;
return $self->{impl}->chown($ctx, $path, $owner, $group);
}

sub df{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
return $self->{impl}->df($ctx);
}

sub enterSafeMode{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
return $self->{impl}->enterSafeMode($ctx);
}

sub getBlocks{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $offset = ($request->{'offset'}) ? $request->{'offset'} : undef;
my $length = ($request->{'length'}) ? $request->{'length'} : undef;
return $self->{impl}->getBlocks($ctx, $path, $offset, $length);
}

sub getDatanodeReport{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $type = ($request->{'type'}) ? $request->{'type'} : undef;
return $self->{impl}->getDatanodeReport($ctx, $type);
}

sub getHealthReport{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
return $self->{impl}->getHealthReport($ctx);
}

sub getPreferredBlockSize{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
return $self->{impl}->getPreferredBlockSize($ctx, $path);
}

sub isInSafeMode{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
return $self->{impl}->isInSafeMode($ctx);
}

sub leaveSafeMode{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
return $self->{impl}->leaveSafeMode($ctx);
}

sub ls{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
return $self->{impl}->ls($ctx, $path);
}

sub mkdirhier{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $perms = ($request->{'perms'}) ? $request->{'perms'} : undef;
return $self->{impl}->mkdirhier($ctx, $path, $perms);
}

sub refreshNodes{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
return $self->{impl}->refreshNodes($ctx);
}

sub rename{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $newPath = ($request->{'newPath'}) ? $request->{'newPath'} : undef;
return $self->{impl}->rename($ctx, $path, $newPath);
}

sub reportBadBlocks{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $blocks = ($request->{'blocks'}) ? $request->{'blocks'} : undef;
return $self->{impl}->reportBadBlocks($ctx, $blocks);
}

sub stat{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
return $self->{impl}->stat($ctx, $path);
}

sub setQuota{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $namespaceQuota = ($request->{'namespaceQuota'}) ? $request->{'namespaceQuota'} : undef;
my $diskspaceQuota = ($request->{'diskspaceQuota'}) ? $request->{'diskspaceQuota'} : undef;
return $self->{impl}->setQuota($ctx, $path, $namespaceQuota, $diskspaceQuota);
}

sub setReplication{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $replication = ($request->{'replication'}) ? $request->{'replication'} : undef;
return $self->{impl}->setReplication($ctx, $path, $replication);
}

sub unlink{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $recursive = ($request->{'recursive'}) ? $request->{'recursive'} : undef;
return $self->{impl}->unlink($ctx, $path, $recursive);
}

sub utime{
my $self = shift;
my $request = shift;

my $ctx = ($request->{'ctx'}) ? $request->{'ctx'} : undef;
my $path = ($request->{'path'}) ? $request->{'path'} : undef;
my $atime = ($request->{'atime'}) ? $request->{'atime'} : undef;
my $mtime = ($request->{'mtime'}) ? $request->{'mtime'} : undef;
return $self->{impl}->utime($ctx, $path, $atime, $mtime);
}

sub datanodeUp{
my $self = shift;
my $request = shift;

my $name = ($request->{'name'}) ? $request->{'name'} : undef;
my $storage = ($request->{'storage'}) ? $request->{'storage'} : undef;
my $thriftPort = ($request->{'thriftPort'}) ? $request->{'thriftPort'} : undef;
return $self->{impl}->datanodeUp($name, $storage, $thriftPort);
}

sub datanodeDown{
my $self = shift;
my $request = shift;

my $name = ($request->{'name'}) ? $request->{'name'} : undef;
my $storage = ($request->{'storage'}) ? $request->{'storage'} : undef;
my $thriftPort = ($request->{'thriftPort'}) ? $request->{'thriftPort'} : undef;
return $self->{impl}->datanodeDown($name, $storage, $thriftPort);
}

package Hadoop::API::NamenodeClient;
use base('Hadoop::API::HadoopServiceBaseClient');
use base('Hadoop::API::NamenodeIf');
sub new {
my $classname = shift;
my $input     = shift;
my $output    = shift;
my $self      = {};
  $self = $classname->SUPER::new($input, $output);
return bless($self,$classname);
}

sub chmod{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $perms = shift;

$self->send_chmod($ctx, $path, $perms);
$self->recv_chmod();
}

sub send_chmod{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $perms = shift;

$self->{output}->writeMessageBegin('chmod', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_chmod_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{perms} = $perms;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_chmod{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_chmod_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub chown{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $owner = shift;
  my $group = shift;

$self->send_chown($ctx, $path, $owner, $group);
$self->recv_chown();
}

sub send_chown{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $owner = shift;
  my $group = shift;

$self->{output}->writeMessageBegin('chown', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_chown_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{owner} = $owner;
$args->{group} = $group;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_chown{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_chown_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub df{
  my $self = shift;
  my $ctx = shift;

$self->send_df($ctx);
return $self->recv_df();
}

sub send_df{
  my $self = shift;
  my $ctx = shift;

$self->{output}->writeMessageBegin('df', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_df_args();
$args->{ctx} = $ctx;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_df{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_df_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "df failed: unknown result";
}
sub enterSafeMode{
  my $self = shift;
  my $ctx = shift;

$self->send_enterSafeMode($ctx);
$self->recv_enterSafeMode();
}

sub send_enterSafeMode{
  my $self = shift;
  my $ctx = shift;

$self->{output}->writeMessageBegin('enterSafeMode', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_enterSafeMode_args();
$args->{ctx} = $ctx;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_enterSafeMode{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_enterSafeMode_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub getBlocks{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $offset = shift;
  my $length = shift;

$self->send_getBlocks($ctx, $path, $offset, $length);
return $self->recv_getBlocks();
}

sub send_getBlocks{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $offset = shift;
  my $length = shift;

$self->{output}->writeMessageBegin('getBlocks', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_getBlocks_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{offset} = $offset;
$args->{length} = $length;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_getBlocks{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_getBlocks_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "getBlocks failed: unknown result";
}
sub getDatanodeReport{
  my $self = shift;
  my $ctx = shift;
  my $type = shift;

$self->send_getDatanodeReport($ctx, $type);
return $self->recv_getDatanodeReport();
}

sub send_getDatanodeReport{
  my $self = shift;
  my $ctx = shift;
  my $type = shift;

$self->{output}->writeMessageBegin('getDatanodeReport', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_getDatanodeReport_args();
$args->{ctx} = $ctx;
$args->{type} = $type;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_getDatanodeReport{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_getDatanodeReport_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "getDatanodeReport failed: unknown result";
}
sub getHealthReport{
  my $self = shift;
  my $ctx = shift;

$self->send_getHealthReport($ctx);
return $self->recv_getHealthReport();
}

sub send_getHealthReport{
  my $self = shift;
  my $ctx = shift;

$self->{output}->writeMessageBegin('getHealthReport', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_getHealthReport_args();
$args->{ctx} = $ctx;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_getHealthReport{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_getHealthReport_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "getHealthReport failed: unknown result";
}
sub getPreferredBlockSize{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

$self->send_getPreferredBlockSize($ctx, $path);
return $self->recv_getPreferredBlockSize();
}

sub send_getPreferredBlockSize{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

$self->{output}->writeMessageBegin('getPreferredBlockSize', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_getPreferredBlockSize_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_getPreferredBlockSize{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_getPreferredBlockSize_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "getPreferredBlockSize failed: unknown result";
}
sub isInSafeMode{
  my $self = shift;
  my $ctx = shift;

$self->send_isInSafeMode($ctx);
return $self->recv_isInSafeMode();
}

sub send_isInSafeMode{
  my $self = shift;
  my $ctx = shift;

$self->{output}->writeMessageBegin('isInSafeMode', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_isInSafeMode_args();
$args->{ctx} = $ctx;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_isInSafeMode{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_isInSafeMode_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "isInSafeMode failed: unknown result";
}
sub leaveSafeMode{
  my $self = shift;
  my $ctx = shift;

$self->send_leaveSafeMode($ctx);
$self->recv_leaveSafeMode();
}

sub send_leaveSafeMode{
  my $self = shift;
  my $ctx = shift;

$self->{output}->writeMessageBegin('leaveSafeMode', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_leaveSafeMode_args();
$args->{ctx} = $ctx;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_leaveSafeMode{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_leaveSafeMode_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub ls{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

$self->send_ls($ctx, $path);
return $self->recv_ls();
}

sub send_ls{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

$self->{output}->writeMessageBegin('ls', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_ls_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_ls{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_ls_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "ls failed: unknown result";
}
sub mkdirhier{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $perms = shift;

$self->send_mkdirhier($ctx, $path, $perms);
return $self->recv_mkdirhier();
}

sub send_mkdirhier{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $perms = shift;

$self->{output}->writeMessageBegin('mkdirhier', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_mkdirhier_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{perms} = $perms;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_mkdirhier{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_mkdirhier_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "mkdirhier failed: unknown result";
}
sub refreshNodes{
  my $self = shift;
  my $ctx = shift;

$self->send_refreshNodes($ctx);
$self->recv_refreshNodes();
}

sub send_refreshNodes{
  my $self = shift;
  my $ctx = shift;

$self->{output}->writeMessageBegin('refreshNodes', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_refreshNodes_args();
$args->{ctx} = $ctx;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_refreshNodes{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_refreshNodes_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub rename{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $newPath = shift;

$self->send_rename($ctx, $path, $newPath);
return $self->recv_rename();
}

sub send_rename{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $newPath = shift;

$self->{output}->writeMessageBegin('rename', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_rename_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{newPath} = $newPath;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_rename{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_rename_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "rename failed: unknown result";
}
sub reportBadBlocks{
  my $self = shift;
  my $ctx = shift;
  my $blocks = shift;

$self->send_reportBadBlocks($ctx, $blocks);
$self->recv_reportBadBlocks();
}

sub send_reportBadBlocks{
  my $self = shift;
  my $ctx = shift;
  my $blocks = shift;

$self->{output}->writeMessageBegin('reportBadBlocks', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_reportBadBlocks_args();
$args->{ctx} = $ctx;
$args->{blocks} = $blocks;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_reportBadBlocks{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_reportBadBlocks_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub stat{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

$self->send_stat($ctx, $path);
return $self->recv_stat();
}

sub send_stat{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;

$self->{output}->writeMessageBegin('stat', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_stat_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_stat{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_stat_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "stat failed: unknown result";
}
sub setQuota{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $namespaceQuota = shift;
  my $diskspaceQuota = shift;

$self->send_setQuota($ctx, $path, $namespaceQuota, $diskspaceQuota);
$self->recv_setQuota();
}

sub send_setQuota{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $namespaceQuota = shift;
  my $diskspaceQuota = shift;

$self->{output}->writeMessageBegin('setQuota', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_setQuota_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{namespaceQuota} = $namespaceQuota;
$args->{diskspaceQuota} = $diskspaceQuota;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_setQuota{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_setQuota_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub setReplication{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $replication = shift;

$self->send_setReplication($ctx, $path, $replication);
return $self->recv_setReplication();
}

sub send_setReplication{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $replication = shift;

$self->{output}->writeMessageBegin('setReplication', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_setReplication_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{replication} = $replication;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_setReplication{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_setReplication_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "setReplication failed: unknown result";
}
sub unlink{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $recursive = shift;

$self->send_unlink($ctx, $path, $recursive);
return $self->recv_unlink();
}

sub send_unlink{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $recursive = shift;

$self->{output}->writeMessageBegin('unlink', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_unlink_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{recursive} = $recursive;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_unlink{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_unlink_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{success} ) {
  return $result->{success};
}
if (defined $result->{err}) {
  die $result->{err};
}
die "unlink failed: unknown result";
}
sub utime{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $atime = shift;
  my $mtime = shift;

$self->send_utime($ctx, $path, $atime, $mtime);
$self->recv_utime();
}

sub send_utime{
  my $self = shift;
  my $ctx = shift;
  my $path = shift;
  my $atime = shift;
  my $mtime = shift;

$self->{output}->writeMessageBegin('utime', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_utime_args();
$args->{ctx} = $ctx;
$args->{path} = $path;
$args->{atime} = $atime;
$args->{mtime} = $mtime;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_utime{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_utime_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

if (defined $result->{err}) {
  die $result->{err};
}
return;
}
sub datanodeUp{
  my $self = shift;
  my $name = shift;
  my $storage = shift;
  my $thriftPort = shift;

$self->send_datanodeUp($name, $storage, $thriftPort);
$self->recv_datanodeUp();
}

sub send_datanodeUp{
  my $self = shift;
  my $name = shift;
  my $storage = shift;
  my $thriftPort = shift;

$self->{output}->writeMessageBegin('datanodeUp', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_datanodeUp_args();
$args->{name} = $name;
$args->{storage} = $storage;
$args->{thriftPort} = $thriftPort;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_datanodeUp{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_datanodeUp_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

return;
}
sub datanodeDown{
  my $self = shift;
  my $name = shift;
  my $storage = shift;
  my $thriftPort = shift;

$self->send_datanodeDown($name, $storage, $thriftPort);
$self->recv_datanodeDown();
}

sub send_datanodeDown{
  my $self = shift;
  my $name = shift;
  my $storage = shift;
  my $thriftPort = shift;

$self->{output}->writeMessageBegin('datanodeDown', TMessageType::CALL, $self->{seqid});
my $args = new Hadoop::API::Namenode_datanodeDown_args();
$args->{name} = $name;
$args->{storage} = $storage;
$args->{thriftPort} = $thriftPort;
$args->write($self->{output});
$self->{output}->writeMessageEnd();
$self->{output}->getTransport()->flush();
}

sub recv_datanodeDown{
  my $self = shift;

my $rseqid = 0;
my $fname;
my $mtype = 0;

$self->{input}->readMessageBegin(\$fname, \$mtype, \$rseqid);
if ($mtype == TMessageType::EXCEPTION) {
  my $x = new TApplicationException();
  $x->read($self->{input});
  $self->{input}->readMessageEnd();
  die $x;
}
my $result = new Hadoop::API::Namenode_datanodeDown_result();
$result->read($self->{input});
$self->{input}->readMessageEnd();

return;
}
package Hadoop::API::NamenodeProcessor;
use base('Hadoop::API::HadoopServiceBaseProcessor');
sub process {
  my $self   = shift;
  my $input  = shift;
  my $output = shift;
  my $rseqid = 0;
  my $fname  = undef;
  my $mtype  = 0;

  $input->readMessageBegin(\$fname, \$mtype, \$rseqid);
  my $methodname = 'process_'.$fname;
  if (!method_exists($self, $methodname)) {
    $input->skip(TType::STRUCT);
    $input->readMessageEnd();
    my $x = new TApplicationException('Function '.$fname.' not implemented.', TApplicationException::UNKNOWN_METHOD);
    $output->writeMessageBegin($fname, TMessageType::EXCEPTION, $rseqid);
    $x->write($output);
    $output->writeMessageEnd();
    $output->getTransport()->flush();
    return;
  }
  $self->$methodname($rseqid, $input, $output);
  return 1;
}

sub process_chmod{
  my $self = shift;
  my ($seqid, $input, $output); 
  my $args = new Hadoop::API::Namenode_chmod_args();
  $args->read($input);
  $input->readMessageEnd();
  my $result = new Hadoop::API::Namenode_chmod_result();
  eval {
    $self->{handler}->chmod($args->ctx, $args->path, $args->perms);
  }; if( UNIVERSAL::isa($@,'IOException') ){ 
    $result->{err} = $@;
  }
  $output->writeMessageBegin('chmod', TMessageType::REPLY, $seqid);
  $result->write($output);
  $output->getTransport()->flush();
}
sub process_chown{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_chown_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_chown_result();
eval {
  $self->{handler}->chown($args->ctx, $args->path, $args->owner, $args->group);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
  $result->{err} = $@;
}
$output->writeMessageBegin('chown', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_df{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_df_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_df_result();
eval {
$result->{success} = $self->{handler}->df($args->ctx);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('df', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_enterSafeMode{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_enterSafeMode_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_enterSafeMode_result();
eval {
$self->{handler}->enterSafeMode($args->ctx);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('enterSafeMode', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_getBlocks{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_getBlocks_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_getBlocks_result();
eval {
$result->{success} = $self->{handler}->getBlocks($args->ctx, $args->path, $args->offset, $args->length);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('getBlocks', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_getDatanodeReport{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_getDatanodeReport_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_getDatanodeReport_result();
eval {
$result->{success} = $self->{handler}->getDatanodeReport($args->ctx, $args->type);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('getDatanodeReport', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_getHealthReport{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_getHealthReport_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_getHealthReport_result();
eval {
$result->{success} = $self->{handler}->getHealthReport($args->ctx);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('getHealthReport', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_getPreferredBlockSize{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_getPreferredBlockSize_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_getPreferredBlockSize_result();
eval {
$result->{success} = $self->{handler}->getPreferredBlockSize($args->ctx, $args->path);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('getPreferredBlockSize', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_isInSafeMode{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_isInSafeMode_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_isInSafeMode_result();
eval {
$result->{success} = $self->{handler}->isInSafeMode($args->ctx);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('isInSafeMode', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_leaveSafeMode{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_leaveSafeMode_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_leaveSafeMode_result();
eval {
$self->{handler}->leaveSafeMode($args->ctx);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('leaveSafeMode', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_ls{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_ls_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_ls_result();
eval {
$result->{success} = $self->{handler}->ls($args->ctx, $args->path);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('ls', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_mkdirhier{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_mkdirhier_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_mkdirhier_result();
eval {
$result->{success} = $self->{handler}->mkdirhier($args->ctx, $args->path, $args->perms);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('mkdirhier', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_refreshNodes{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_refreshNodes_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_refreshNodes_result();
eval {
$self->{handler}->refreshNodes($args->ctx);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('refreshNodes', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_rename{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_rename_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_rename_result();
eval {
$result->{success} = $self->{handler}->rename($args->ctx, $args->path, $args->newPath);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('rename', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_reportBadBlocks{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_reportBadBlocks_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_reportBadBlocks_result();
eval {
$self->{handler}->reportBadBlocks($args->ctx, $args->blocks);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('reportBadBlocks', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_stat{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_stat_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_stat_result();
eval {
$result->{success} = $self->{handler}->stat($args->ctx, $args->path);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('stat', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_setQuota{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_setQuota_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_setQuota_result();
eval {
$self->{handler}->setQuota($args->ctx, $args->path, $args->namespaceQuota, $args->diskspaceQuota);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('setQuota', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_setReplication{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_setReplication_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_setReplication_result();
eval {
$result->{success} = $self->{handler}->setReplication($args->ctx, $args->path, $args->replication);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('setReplication', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_unlink{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_unlink_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_unlink_result();
eval {
$result->{success} = $self->{handler}->unlink($args->ctx, $args->path, $args->recursive);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('unlink', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_utime{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_utime_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_utime_result();
eval {
$self->{handler}->utime($args->ctx, $args->path, $args->atime, $args->mtime);
}; if( UNIVERSAL::isa($@,'IOException') ){ 
$result->{err} = $@;
}
$output->writeMessageBegin('utime', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_datanodeUp{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_datanodeUp_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_datanodeUp_result();
$self->{handler}->datanodeUp($args->name, $args->storage, $args->thriftPort);
$output->writeMessageBegin('datanodeUp', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
sub process_datanodeDown{
my $self = shift;
my ($seqid, $input, $output); 
my $args = new Hadoop::API::Namenode_datanodeDown_args();
$args->read($input);
$input->readMessageEnd();
my $result = new Hadoop::API::Namenode_datanodeDown_result();
$self->{handler}->datanodeDown($args->name, $args->storage, $args->thriftPort);
$output->writeMessageBegin('datanodeDown', TMessageType::REPLY, $seqid);
$result->write($output);
$output->getTransport()->flush();
}
1;
